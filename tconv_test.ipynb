{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t_conv import t_conv\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dilated RS layer, K[2]\n",
      "l0k2 - Dil: 1\n",
      "Created dilated RS layer, K[2]\n",
      "l1k2 - Dil: 2\n",
      "Created dilated RS layer, K[2]\n",
      "l2k2 - Dil: 4\n",
      "Created dilated RS layer, K[2]\n",
      "l3k2 - Dil: 8\n",
      "Created dilated RS layer, K[2]\n",
      "l4k2 - Dil: 16\n",
      "Created dilated RS layer, K[2]\n",
      "l5k2 - Dil: 32\n",
      "Created dilated RS layer, K[2]\n",
      "l6k2 - Dil: 1\n",
      "Created dilated RS layer, K[2]\n",
      "l7k2 - Dil: 2\n",
      "Created dilated RS layer, K[2]\n",
      "l8k2 - Dil: 4\n",
      "Created dilated RS layer, K[2]\n",
      "l9k2 - Dil: 8\n",
      "Created dilated RS layer, K[2]\n",
      "l10k2 - Dil: 16\n",
      "Created dilated RS layer, K[2]\n",
      "l11k2 - Dil: 1\n"
     ]
    }
   ],
   "source": [
    "x = t_conv(in_channels=10, kernel_size=2,\n",
    "           in_size=100, output_size=5,\n",
    "           consumption='full', normalization='switch', output='default',\n",
    "           residual=True, residual_conv=True,\n",
    "           skip_connections=False, skip_conv=True,\n",
    "           debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand(1,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10, 100])\n",
      "tensor([[[1.7208e-01, 1.0842e-01, 8.4705e-01, 7.9457e-01, 3.1715e-01,\n",
      "          6.5110e-01, 9.2858e-02, 5.9311e-01, 2.9694e-02, 2.0820e-01,\n",
      "          9.2254e-01, 5.7273e-01, 4.0704e-01, 9.8896e-01, 2.5083e-01,\n",
      "          7.2850e-01, 9.9498e-01, 5.9761e-01, 7.7472e-01, 3.7364e-01,\n",
      "          8.3688e-01, 3.6740e-01, 7.2467e-01, 8.6205e-01, 5.1183e-01,\n",
      "          9.6081e-01, 5.2290e-01, 7.9295e-01, 7.7542e-01, 8.7413e-01,\n",
      "          4.5913e-01, 3.3493e-01, 2.5906e-01, 2.3292e-01, 7.7036e-01,\n",
      "          8.9046e-01, 7.9792e-01, 9.1534e-01, 8.1000e-01, 4.4702e-01,\n",
      "          6.1666e-01, 6.2383e-01, 6.4170e-01, 7.9172e-01, 9.7463e-01,\n",
      "          7.7510e-01, 2.9461e-01, 1.3281e-02, 8.8401e-01, 8.2205e-01,\n",
      "          8.2383e-01, 3.1881e-01, 4.7434e-01, 2.4655e-01, 8.7886e-01,\n",
      "          6.1207e-01, 3.9799e-01, 3.5984e-02, 8.1659e-01, 2.1719e-01,\n",
      "          7.4654e-01, 9.0525e-01, 5.8736e-02, 3.9674e-01, 2.4264e-01,\n",
      "          9.3877e-01, 4.5493e-01, 3.3221e-01, 4.5008e-01, 5.8873e-01,\n",
      "          3.4682e-01, 1.4335e-01, 6.7887e-01, 4.6965e-01, 4.2078e-01,\n",
      "          6.0807e-01, 2.5523e-01, 7.7498e-01, 5.9413e-02, 9.5337e-01,\n",
      "          6.6048e-01, 9.0760e-01, 3.0178e-02, 2.8335e-01, 3.2842e-01,\n",
      "          4.6997e-01, 1.2771e-01, 1.7033e-01, 5.8382e-01, 6.0787e-01,\n",
      "          1.6322e-01, 2.4482e-01, 3.3900e-01, 3.9231e-01, 2.5252e-01,\n",
      "          4.5480e-01, 3.5272e-01, 7.1575e-01, 1.3369e-01, 4.0904e-01],\n",
      "         [5.6409e-01, 1.3796e-01, 4.8125e-01, 7.1710e-01, 5.6873e-01,\n",
      "          2.9813e-01, 9.5625e-01, 1.7725e-01, 1.2176e-01, 2.7863e-01,\n",
      "          7.5692e-01, 1.3836e-01, 4.0491e-01, 5.2319e-01, 5.8056e-01,\n",
      "          9.7690e-01, 3.8958e-01, 9.8363e-01, 5.6651e-02, 3.2318e-01,\n",
      "          5.4388e-01, 6.0128e-01, 8.6681e-01, 4.7573e-01, 4.7089e-01,\n",
      "          1.5159e-01, 6.0277e-01, 5.8502e-01, 7.2826e-01, 8.2601e-01,\n",
      "          5.2505e-01, 9.7150e-01, 2.0627e-01, 8.1101e-01, 7.7310e-02,\n",
      "          7.0219e-01, 1.8738e-01, 9.8225e-02, 3.6677e-01, 9.1139e-01,\n",
      "          7.8733e-01, 7.8220e-01, 5.8286e-01, 4.7145e-01, 6.4036e-02,\n",
      "          2.5063e-02, 4.2387e-01, 9.4085e-01, 8.0966e-01, 2.9419e-01,\n",
      "          4.5096e-01, 8.1474e-04, 5.5948e-01, 7.4842e-01, 8.7056e-01,\n",
      "          6.8914e-01, 5.7217e-01, 3.7695e-01, 1.9669e-01, 3.5607e-02,\n",
      "          5.9377e-01, 9.9161e-01, 5.4750e-01, 8.0364e-01, 1.9393e-01,\n",
      "          2.6863e-02, 1.5707e-01, 7.2370e-01, 3.4858e-01, 9.8642e-01,\n",
      "          8.3913e-01, 5.7490e-01, 9.4107e-01, 9.2712e-01, 3.4499e-01,\n",
      "          5.4795e-01, 4.8213e-01, 1.4421e-01, 2.8820e-01, 1.3939e-01,\n",
      "          2.0858e-02, 6.3358e-02, 4.6408e-01, 2.3078e-01, 5.5621e-01,\n",
      "          1.4976e-02, 5.0093e-01, 7.6291e-01, 5.3907e-01, 6.3408e-01,\n",
      "          2.5559e-01, 2.3685e-01, 4.0705e-01, 6.8747e-02, 4.6409e-01,\n",
      "          9.0703e-01, 4.0404e-01, 4.1566e-02, 1.6384e-01, 2.8331e-01],\n",
      "         [9.9217e-01, 2.7878e-01, 5.3860e-01, 1.0587e-01, 2.2148e-02,\n",
      "          4.7287e-01, 8.8176e-01, 4.6100e-02, 6.7382e-01, 6.0751e-01,\n",
      "          8.9457e-01, 4.3907e-01, 1.9408e-01, 5.4552e-01, 9.5241e-01,\n",
      "          9.3772e-01, 2.4111e-01, 7.7492e-02, 4.0166e-01, 7.9669e-01,\n",
      "          1.4643e-01, 4.1093e-01, 8.2840e-01, 9.1259e-01, 6.6060e-01,\n",
      "          7.8522e-01, 5.3709e-01, 3.2315e-01, 8.1111e-01, 9.9345e-01,\n",
      "          9.8611e-01, 4.5760e-01, 2.2504e-01, 3.0165e-01, 4.0450e-01,\n",
      "          3.6823e-01, 8.5357e-01, 8.4407e-01, 5.8770e-01, 4.3434e-01,\n",
      "          3.4426e-01, 2.6396e-01, 9.4304e-01, 6.2748e-02, 1.1380e-01,\n",
      "          8.9744e-01, 5.6894e-02, 6.0517e-01, 3.5934e-01, 4.4666e-01,\n",
      "          6.0519e-01, 1.9768e-01, 2.6876e-01, 8.7362e-01, 4.2682e-01,\n",
      "          5.0312e-01, 7.8736e-01, 7.3201e-01, 1.3135e-01, 7.9203e-01,\n",
      "          4.3810e-01, 8.5618e-01, 7.0650e-01, 8.6475e-03, 4.1414e-01,\n",
      "          2.6570e-01, 2.8478e-01, 6.5269e-01, 5.2653e-01, 9.4974e-01,\n",
      "          7.0483e-01, 1.6979e-02, 6.6531e-01, 2.1188e-01, 1.9769e-01,\n",
      "          4.5219e-01, 4.6707e-01, 6.1969e-03, 8.6517e-01, 8.6263e-01,\n",
      "          7.5604e-01, 1.9317e-01, 4.0926e-02, 8.3363e-01, 5.4127e-01,\n",
      "          3.2196e-01, 5.1837e-01, 8.9392e-01, 4.0979e-01, 6.8270e-01,\n",
      "          7.4075e-01, 1.4426e-01, 8.8914e-01, 8.9674e-01, 3.2615e-01,\n",
      "          4.8482e-01, 6.3771e-01, 9.0376e-01, 3.6620e-01, 8.8142e-01],\n",
      "         [6.4243e-01, 1.0544e-02, 9.3389e-01, 3.5589e-01, 7.0617e-01,\n",
      "          4.6003e-01, 9.0885e-01, 3.7960e-01, 5.1706e-02, 3.0536e-01,\n",
      "          7.9915e-01, 4.0034e-01, 1.1430e-01, 9.6489e-01, 8.8840e-01,\n",
      "          1.3831e-01, 3.2977e-01, 6.4619e-01, 1.3454e-01, 9.7270e-01,\n",
      "          4.3740e-01, 5.2638e-01, 3.4266e-01, 5.7928e-01, 4.7882e-01,\n",
      "          2.5059e-01, 6.7511e-01, 4.2835e-01, 8.8721e-01, 6.3817e-01,\n",
      "          6.7916e-01, 4.3489e-01, 6.9707e-01, 6.9778e-01, 4.1573e-01,\n",
      "          9.7291e-01, 3.6482e-01, 4.1504e-01, 6.4911e-01, 8.9721e-01,\n",
      "          8.4637e-02, 4.6225e-01, 1.1430e-01, 7.5547e-01, 6.2157e-01,\n",
      "          5.1374e-02, 3.2665e-01, 5.3979e-01, 4.2918e-01, 7.7066e-01,\n",
      "          9.2282e-01, 8.2829e-01, 6.2882e-01, 8.7932e-02, 8.2098e-02,\n",
      "          2.6184e-01, 6.0612e-04, 9.4726e-01, 1.9192e-01, 4.5002e-01,\n",
      "          4.8168e-01, 2.0403e-01, 7.5720e-02, 4.7795e-01, 8.4300e-01,\n",
      "          7.1597e-01, 1.7827e-01, 4.6068e-02, 5.8021e-01, 8.3904e-01,\n",
      "          6.3059e-02, 3.1943e-01, 2.2675e-01, 1.9446e-01, 7.2253e-02,\n",
      "          8.8138e-01, 8.9557e-01, 9.0117e-01, 2.1702e-01, 3.4301e-01,\n",
      "          9.5127e-01, 9.2417e-01, 3.2578e-01, 2.9392e-01, 4.1865e-01,\n",
      "          4.2902e-01, 9.2012e-01, 1.1057e-01, 1.3972e-01, 5.2536e-02,\n",
      "          8.1666e-01, 7.7466e-01, 1.5710e-01, 8.2576e-01, 9.9293e-01,\n",
      "          5.1624e-01, 5.7723e-01, 6.1222e-01, 9.0430e-01, 7.6259e-01],\n",
      "         [7.6729e-01, 2.3474e-01, 9.8184e-01, 4.3628e-01, 8.1096e-01,\n",
      "          9.6770e-01, 1.7405e-01, 8.1388e-01, 3.9781e-01, 2.4446e-01,\n",
      "          7.5868e-01, 8.2898e-01, 8.8940e-01, 9.9856e-01, 5.5992e-01,\n",
      "          9.5980e-01, 9.6143e-01, 7.5642e-01, 8.0591e-02, 8.9475e-01,\n",
      "          4.3064e-01, 9.1839e-01, 9.7948e-01, 5.5315e-01, 4.0215e-01,\n",
      "          4.8560e-01, 4.6222e-01, 4.4682e-01, 7.8751e-01, 9.8068e-01,\n",
      "          3.7773e-01, 3.1386e-01, 5.7809e-01, 8.5189e-01, 1.9520e-01,\n",
      "          6.6351e-01, 9.8037e-01, 2.9916e-01, 9.6549e-01, 1.1589e-02,\n",
      "          1.7716e-01, 6.2823e-02, 4.3806e-01, 9.8552e-01, 8.5936e-01,\n",
      "          5.7409e-01, 1.4835e-01, 8.1235e-01, 4.9591e-01, 2.6170e-01,\n",
      "          3.8955e-01, 4.5945e-01, 3.8098e-01, 3.6792e-01, 9.3295e-01,\n",
      "          4.4237e-01, 5.3796e-01, 7.3057e-01, 7.6709e-01, 1.9864e-02,\n",
      "          6.6960e-01, 7.6164e-01, 3.8516e-01, 2.8844e-01, 9.4497e-02,\n",
      "          1.1037e-01, 9.6704e-01, 4.7823e-01, 2.0898e-01, 3.4990e-01,\n",
      "          1.4017e-01, 3.3754e-01, 4.0108e-01, 1.1871e-01, 1.3981e-01,\n",
      "          3.2470e-01, 1.9103e-01, 1.0680e-01, 2.4627e-01, 4.5502e-02,\n",
      "          1.0609e-01, 7.0045e-01, 5.1781e-01, 1.2245e-01, 6.2000e-01,\n",
      "          2.9401e-01, 1.3027e-01, 2.6763e-03, 6.4515e-01, 2.4810e-01,\n",
      "          2.3772e-01, 8.3512e-01, 1.2017e-01, 6.4151e-01, 3.4744e-01,\n",
      "          8.7069e-02, 4.8461e-02, 3.3967e-02, 3.0616e-01, 1.8765e-01],\n",
      "         [9.5498e-01, 2.4753e-01, 2.0279e-02, 2.9049e-01, 1.8833e-01,\n",
      "          5.7777e-01, 8.5891e-01, 1.1705e-01, 4.2382e-01, 6.4506e-01,\n",
      "          1.2971e-01, 7.6981e-01, 1.1757e-02, 3.0116e-01, 4.2143e-01,\n",
      "          4.8109e-01, 1.6496e-01, 3.1746e-02, 1.2372e-01, 1.5326e-02,\n",
      "          1.1883e-01, 4.3401e-01, 9.5531e-02, 3.0716e-01, 2.7625e-01,\n",
      "          4.1485e-04, 5.3933e-01, 5.7571e-01, 3.7745e-01, 6.4766e-01,\n",
      "          4.6789e-01, 2.4981e-01, 3.8602e-01, 4.6524e-01, 8.7858e-01,\n",
      "          3.4082e-01, 6.0127e-01, 3.1476e-01, 8.9514e-01, 9.2125e-01,\n",
      "          4.7446e-01, 9.2636e-01, 6.3742e-01, 8.5551e-01, 3.6709e-01,\n",
      "          6.8276e-01, 4.8553e-01, 6.2306e-01, 8.9195e-01, 2.4173e-01,\n",
      "          2.8121e-02, 1.8637e-02, 8.1133e-01, 3.5529e-01, 5.1276e-01,\n",
      "          9.6489e-01, 6.9307e-01, 2.6211e-01, 7.2724e-01, 9.3941e-01,\n",
      "          4.5974e-01, 3.6900e-01, 9.0435e-01, 1.2013e-01, 9.8190e-01,\n",
      "          5.0669e-01, 9.2816e-01, 6.2160e-02, 5.3302e-01, 4.8050e-01,\n",
      "          7.0782e-01, 2.4353e-01, 2.6852e-01, 2.1962e-01, 5.2301e-01,\n",
      "          1.9066e-01, 3.4704e-02, 6.6781e-01, 8.9769e-01, 4.6150e-01,\n",
      "          1.4127e-01, 9.0624e-01, 4.6548e-01, 2.7051e-01, 7.6915e-01,\n",
      "          7.0653e-01, 2.4324e-01, 7.3639e-01, 8.5692e-01, 2.9102e-01,\n",
      "          8.1057e-01, 2.4655e-01, 9.0164e-03, 8.3244e-02, 4.0274e-01,\n",
      "          2.7586e-02, 2.9100e-01, 5.9910e-01, 2.9432e-01, 9.6582e-01],\n",
      "         [2.8952e-01, 5.8644e-01, 3.3654e-01, 8.4901e-01, 2.4316e-01,\n",
      "          6.2592e-01, 1.2033e-01, 3.6950e-01, 3.3094e-01, 9.7015e-01,\n",
      "          1.3812e-01, 3.6538e-01, 4.9357e-01, 6.4125e-01, 5.7493e-01,\n",
      "          5.4905e-01, 8.9368e-01, 8.8787e-01, 7.9293e-01, 6.6826e-01,\n",
      "          2.4292e-01, 4.3319e-01, 4.5539e-01, 9.5793e-01, 5.1973e-02,\n",
      "          2.7671e-01, 3.1104e-01, 9.1069e-02, 5.8896e-01, 4.5402e-01,\n",
      "          4.8496e-01, 1.4067e-02, 8.3273e-01, 2.5091e-01, 2.6941e-01,\n",
      "          6.8302e-02, 4.2992e-01, 7.9224e-01, 4.3072e-01, 1.0428e-01,\n",
      "          5.3047e-01, 5.6972e-01, 9.0314e-01, 2.0035e-01, 6.7550e-01,\n",
      "          4.8220e-01, 5.0148e-01, 7.0116e-01, 4.3320e-01, 5.6184e-01,\n",
      "          8.8754e-01, 3.0766e-01, 1.8891e-01, 4.9320e-01, 1.6426e-01,\n",
      "          3.6350e-01, 8.0796e-01, 2.9852e-01, 8.8145e-01, 6.0294e-01,\n",
      "          6.1123e-01, 8.7909e-01, 9.9611e-01, 4.4557e-01, 4.1809e-01,\n",
      "          6.8015e-01, 6.0486e-01, 6.3454e-01, 7.6593e-01, 1.9953e-01,\n",
      "          5.4470e-01, 1.9093e-01, 9.8498e-02, 6.7910e-01, 7.8642e-01,\n",
      "          8.0462e-01, 7.1820e-01, 3.0317e-01, 8.2759e-02, 1.5441e-01,\n",
      "          5.3356e-02, 4.4726e-01, 6.1206e-01, 7.6064e-01, 7.2138e-01,\n",
      "          9.8231e-01, 8.5722e-01, 4.0939e-01, 6.2712e-01, 4.5455e-02,\n",
      "          4.2119e-01, 9.4415e-01, 5.1965e-01, 7.1859e-01, 4.7615e-01,\n",
      "          8.7099e-01, 9.2064e-01, 3.6360e-01, 6.0365e-01, 2.7472e-01],\n",
      "         [6.4918e-01, 8.0160e-01, 6.5021e-01, 3.2053e-02, 5.1177e-01,\n",
      "          7.2783e-01, 2.8885e-01, 8.0823e-01, 8.0604e-01, 9.7478e-01,\n",
      "          8.9047e-01, 1.6665e-01, 8.4572e-02, 8.1015e-01, 5.3987e-01,\n",
      "          7.8473e-01, 6.4752e-01, 7.1308e-01, 6.2300e-01, 7.3530e-01,\n",
      "          8.4208e-01, 7.8720e-01, 9.0799e-01, 2.6916e-01, 1.5776e-01,\n",
      "          3.1472e-01, 6.5089e-01, 2.7668e-01, 8.5803e-01, 8.7572e-01,\n",
      "          2.7421e-02, 3.1663e-01, 5.4305e-01, 7.5186e-01, 9.9498e-01,\n",
      "          9.5588e-01, 3.2883e-01, 4.5354e-01, 3.3058e-01, 6.8180e-01,\n",
      "          7.8248e-01, 2.7250e-01, 6.2095e-01, 8.3653e-01, 3.6768e-01,\n",
      "          6.2046e-01, 3.2212e-01, 8.6562e-01, 8.5001e-01, 7.8520e-01,\n",
      "          9.4145e-01, 4.3227e-01, 1.3223e-01, 7.9045e-01, 6.7680e-01,\n",
      "          8.7284e-02, 6.1646e-01, 5.1918e-01, 7.4750e-01, 5.6975e-02,\n",
      "          7.5268e-01, 9.9258e-02, 2.2155e-01, 3.3474e-01, 3.1786e-01,\n",
      "          6.4504e-01, 1.9479e-01, 5.8408e-01, 7.6417e-01, 3.9234e-01,\n",
      "          9.8923e-01, 3.1971e-01, 3.8324e-01, 2.5785e-01, 1.3756e-01,\n",
      "          3.4578e-01, 3.1011e-01, 4.6067e-02, 3.0358e-01, 3.9844e-02,\n",
      "          5.6457e-01, 9.8005e-01, 9.5185e-01, 8.9347e-01, 2.6128e-01,\n",
      "          3.5997e-01, 8.5330e-01, 3.6311e-01, 4.4410e-01, 6.6910e-02,\n",
      "          7.6517e-01, 6.2207e-01, 4.9280e-01, 6.1300e-01, 3.6993e-01,\n",
      "          8.6038e-01, 7.5597e-01, 9.6810e-01, 6.1629e-02, 6.5843e-01],\n",
      "         [3.8624e-01, 9.2606e-01, 2.6619e-01, 2.4351e-01, 7.6534e-01,\n",
      "          2.4574e-01, 9.5094e-01, 8.4164e-01, 9.8805e-01, 4.3167e-01,\n",
      "          8.2932e-01, 8.3322e-01, 2.8173e-01, 3.5874e-01, 5.1327e-02,\n",
      "          1.4568e-01, 5.1501e-01, 3.1572e-01, 9.9394e-01, 1.4577e-01,\n",
      "          8.3880e-01, 1.9714e-01, 2.7639e-01, 9.9346e-01, 6.8896e-01,\n",
      "          9.4033e-02, 2.8835e-01, 7.8402e-01, 3.8451e-01, 6.5928e-01,\n",
      "          9.8603e-01, 7.7304e-01, 1.5375e-01, 4.7443e-01, 3.8008e-01,\n",
      "          5.6149e-01, 2.0515e-01, 2.0500e-01, 1.6637e-01, 9.3069e-01,\n",
      "          5.4800e-01, 5.2068e-01, 2.9618e-01, 3.7054e-01, 5.1678e-01,\n",
      "          7.2135e-01, 7.3650e-01, 7.4026e-01, 1.2692e-01, 4.4107e-01,\n",
      "          1.1824e-01, 9.1292e-01, 5.1153e-01, 7.1463e-02, 2.1019e-01,\n",
      "          4.8397e-01, 8.3697e-01, 5.0822e-01, 3.8298e-01, 9.4072e-01,\n",
      "          3.8205e-01, 9.1291e-01, 4.5174e-01, 7.0313e-02, 2.7110e-01,\n",
      "          6.1395e-01, 3.9288e-01, 3.5477e-02, 7.2168e-01, 7.6050e-01,\n",
      "          6.3859e-01, 7.6051e-01, 5.5341e-01, 9.6785e-01, 7.5744e-01,\n",
      "          9.9464e-01, 7.4889e-01, 6.2908e-01, 6.7573e-02, 6.1028e-01,\n",
      "          8.8392e-01, 8.9410e-01, 2.8333e-01, 3.2467e-02, 1.6561e-02,\n",
      "          6.4039e-01, 7.1558e-01, 3.5921e-01, 3.5681e-02, 4.7717e-01,\n",
      "          8.3374e-01, 8.2788e-01, 4.7475e-01, 9.1340e-02, 7.5862e-01,\n",
      "          4.2199e-01, 8.7578e-01, 2.6450e-01, 9.1128e-01, 2.8999e-01],\n",
      "         [8.3565e-01, 7.1123e-01, 2.5458e-01, 8.5774e-01, 5.5721e-01,\n",
      "          5.3145e-01, 5.6544e-01, 4.7334e-01, 4.3747e-01, 9.0957e-01,\n",
      "          7.4173e-01, 1.3720e-01, 3.3895e-02, 1.1415e-01, 8.2520e-01,\n",
      "          7.2168e-01, 5.3243e-01, 8.2959e-01, 6.0542e-01, 9.7272e-01,\n",
      "          3.6545e-01, 1.5405e-01, 3.3169e-01, 1.4342e-01, 4.8363e-01,\n",
      "          3.5966e-01, 8.0861e-01, 3.2155e-01, 2.5382e-01, 2.3882e-01,\n",
      "          8.3241e-01, 9.8874e-01, 8.0154e-01, 9.4327e-01, 5.6218e-01,\n",
      "          5.4126e-01, 9.0582e-01, 2.9280e-01, 6.9293e-01, 8.9843e-03,\n",
      "          5.5453e-01, 8.7479e-01, 6.7724e-01, 6.9661e-01, 9.2442e-01,\n",
      "          2.7873e-01, 4.5331e-01, 1.6474e-01, 4.0635e-01, 7.5703e-01,\n",
      "          9.2975e-02, 7.7589e-02, 4.7009e-01, 1.0110e-02, 1.6300e-01,\n",
      "          8.0891e-01, 5.8800e-01, 2.1528e-01, 2.1134e-02, 8.0436e-01,\n",
      "          3.4054e-03, 8.7316e-01, 9.6000e-02, 3.9446e-01, 1.3405e-01,\n",
      "          7.3383e-01, 3.0934e-01, 5.2657e-01, 6.0983e-01, 2.4826e-01,\n",
      "          1.0032e-01, 1.0385e-01, 8.2773e-01, 2.0294e-01, 7.6016e-01,\n",
      "          8.1562e-01, 6.0516e-01, 6.8533e-01, 3.6561e-01, 2.1704e-01,\n",
      "          5.6107e-01, 4.9088e-01, 2.8473e-01, 7.8650e-01, 7.7832e-01,\n",
      "          9.6541e-02, 4.9567e-01, 6.9838e-01, 4.2923e-01, 5.4363e-01,\n",
      "          2.3207e-01, 8.8890e-01, 3.7409e-01, 1.4110e-01, 9.3511e-01,\n",
      "          6.5974e-01, 3.4792e-01, 4.7505e-01, 4.5149e-01, 7.4273e-01]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sample.size()}\\n{sample.shape}\\n{sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 5])\n",
      "torch.Size([1, 10, 5])\n",
      "tensor([[[ 0.8969,  1.6002,  0.1901,  2.5183, -0.6032],\n",
      "         [ 0.3344, -0.6159,  1.5714, -0.2028,  2.9316],\n",
      "         [ 0.6574, -1.9348, -1.5458, -0.8363,  0.7277],\n",
      "         [-0.9621,  0.3987, -0.2281,  1.2409,  1.2130],\n",
      "         [ 0.2605,  0.6505,  0.1125,  0.6619,  0.8529],\n",
      "         [ 1.6204, -0.3663, -0.1395, -1.3072, -0.2718],\n",
      "         [ 3.3585, -0.0377,  0.8994,  0.4661,  3.4081],\n",
      "         [-1.5252, -1.6674,  0.1026, -1.1370, -0.6637],\n",
      "         [-0.5753,  0.8884,  0.2972,  1.4075, -0.2459],\n",
      "         [ 2.1986,  1.1369, -0.4956,  0.6989,  0.2140]]],\n",
      "       grad_fn=<AsStridedBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y.size()}\\n{y.shape}\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_backward_hooks': OrderedDict(),\n",
      " '_buffers': OrderedDict(),\n",
      " '_forward_hooks': OrderedDict(),\n",
      " '_forward_pre_hooks': OrderedDict(),\n",
      " '_load_state_dict_pre_hooks': OrderedDict(),\n",
      " '_modules': OrderedDict([('layers',\n",
      "                           ModuleList(\n",
      "  (0): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (1): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (2): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(4,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (3): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (4): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(16,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (5): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(32,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (6): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (7): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (8): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(4,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (9): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (10): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(16,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (11): configurable_dilated_layer(\n",
      "    (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,))\n",
      "    (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")),\n",
      "                          ('norms',\n",
      "                           ModuleList(\n",
      "  (0): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 99), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (1): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 97), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (2): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 93), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (3): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 85), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (4): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 69), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (5): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 37), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (6): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 36), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (7): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 34), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (8): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 30), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (9): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 22), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (10): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 6), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (11): switch_norm1d(\n",
      "    (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (l_norm): LayerNorm((10, 5), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "))]),\n",
      " '_non_persistent_buffers_set': set(),\n",
      " '_parameters': OrderedDict(),\n",
      " '_state_dict_hooks': OrderedDict(),\n",
      " 'f_norm': <function t_conv._calculate_forward.<locals>.<lambda> at 0x7f89486578c0>,\n",
      " 'forward': <bound method t_conv._skip_forward of t_conv(\n",
      "  (layers): ModuleList(\n",
      "    (0): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (1): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (2): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(4,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (3): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (4): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(16,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (5): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(32,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (6): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (7): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (8): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(4,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (9): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (10): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,), dilation=(16,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (11): configurable_dilated_layer(\n",
      "      (dilated_conv): Conv1d(10, 10, kernel_size=(2,), stride=(1,))\n",
      "      (conv_res): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "      (conv_skip): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 99), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 97), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 93), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 85), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (4): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 69), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 37), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (6): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 36), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (7): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 34), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (8): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 30), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (9): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 22), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (10): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 6), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (11): switch_norm1d(\n",
      "      (b_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (i_norm): InstanceNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (l_norm): LayerNorm((10, 5), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")>,\n",
      " 'training': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('pad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e28bccd561e4d4fe208f8faad1f30ec4761c057f84488dc5aee9134c9b77383"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
